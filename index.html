<!DOCTYPE HTML>
<html>
  <head>
    <!-- Google analytics tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NKGR7YZPLV"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-NKGR7YZPLV');
    </script>

    <!-- Title -->
    <title>Nhan Tran - HCI and Robotics Enthusiast</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Isotope JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
    <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>

    <!-- Custom Style -->
    <link rel="stylesheet" href="style.css">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico?">
    <!-- Google Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
    <style>
      @import url('https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap');
    </style>
  </head>

  <body id="body">
    <div id="preloader"></div>
    
    <div id="main">
      <div id="intro">
        <div id="intro-text">
          <h1 id="intro-header">Nhan Tran</h1>
          <div>
              <p>Hi there! I am Nhan Tran (sounds like “Nyun”). </p><br>
              <p>I'm currently a Ph.D. student in <a href="https://www.cs.cornell.edu/people/PhDStudents">Computer Science</a> at Cornell University, advised by Professor <a href="http://abedavis.com/">Abe Davis</a>.</p>
              <br>
              <p>I'm also pursuing a minor in <a href="#filmmaking">Film and Video Production</a> at Cornell's Performing and Media Arts <a href="https://pma.cornell.edu/">program.</a></p>              
              <br>
              <p>Before graduate school, I had two wonderful years in the industry working on robotics perception and human-robot interaction at Robust AI (check out our robot <a href="https://www.robust.ai/">here</a>). Prior to that, I interned, learned, and collaborated with the amazing teams at Robust.AI, Facebook, Google Nest, and NASA/Caltech Jet Propulsion Laboratory.</p>
              <br>

            </div>
            <br>
            <a href="nhan_tran_resume.pdf" target="_blank">CV/Resume</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://github.com/megatran">Github</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://scholar.google.com/citations?user=UpcGCc0AAAAJ&hl=en">G. Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/ttrannhan/">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://twitter.com/megatran23">Twitter/X</a></a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.youtube.com/@NhanTrann/videos">YouTube</a></a>&nbsp;&nbsp;&nbsp;&nbsp;
            <br><br>
            nhan at cs dot cornell dot edu
            <br><br>
          </p>
        </div>
        <div id="intro-image">
          <img src="images/nhan_profile.jpg">
        </div>
      </div>

      <div id="filters" class="button-group">
        <button class="button is-checked" data-filter="*">Show All</button>
        <button class="button" data-filter=".publication">Research</button>
        <button class="button" data-filter=".highlight">Robots</button>
        <button class="button" data-filter=".talk">Films & Videos</button>
        <button class="button" data-filter=".misc">Misc Projects</button>
      </div>

      <div class="grid">

        <!-- Highlights -->
        <div class="list-item highlight description" data-category="highlight">
          I'm fascinated by augmented reality, human-computer interaction, and interactive interfaces for content creation. I’ve had the opportunity to work on projects that bring these interests together, blending creativity with technology. I enjoy rapid prototyping systems and exploring how computational methods from computer graphics, vision, robotics, and computational photography can make an impact in areas like healthcare, content creation, and beyond.          
          
        </div>

        <!-- Preview Videos -->
        <div class="list-item highlight" data-category="highlight">

          <div class="grid-container">            
            <div class="grid-item vertical">
              <!-- <img src="images/projects/hospitalrobot.gif" alt="Hospital Robot"/> -->
              <a href="#hospitalrobot">
                <video class="preview1" playsinline="" muted="" autoplay="" loop=""><source src="images/projects/hospital_robot_sequence2.m4v" type="video/mp4"></video>
              </a>
            </div>
            <div class="grid-item">
              <a href="#visionSliceBot">
                <img src="images/projects/visionSliceBot.gif" alt="Vision Slice Bot"/>
              </a>
            </div>
            <div class="grid-item">
              <a href="#xrhospitalrobot">
                <img src="images/projects/mixedreality_robot.gif" alt="Mixed Reality Robot"/>
              </a>
            </div>
            <!-- <div class="grid-item">
              <a href="#blasterbotica">
                <img src="images/projects/blasterbotica.webp" alt="BlasterBotica"/>
              </a>
            </div> -->
            <div class="grid-item">
              <a href="#mecapture">
                <video class="preview4" playsinline="" muted="" autoplay="" loop=""><source src="images/projects/mecapture_demo.mp4" type="video/mp4"></video>
              </a>
            </div>
            <div class="grid-item">
              <a href="#arpointing">
                <img src="images/research/demo_ar_gesture.gif" alt="AR Gesture Demo"/>
              </a>
            </div>
            <!-- <div class="grid-item">
              <img src="images/research/your_image_here" alt="Your Image Description"/>
            </div> -->
          </div>

        </div>



        <!-- Publications -->
        <div class="section-title list-item " data-category="publication">
          <h2>Publications</h2>
        </div>

        <div class="list-item publication" data-category="publication" id="mecapture">
          <a href="images/projects/mecapture_demo.mp4" class="thumbnail">
            <video class="preview2" playsinline="" muted="" autoplay="" loop=""><source src="images/projects/mecapture_demo.mp4" type="video/mp4"></video>
          </a>
          <div class="project-description">
            <h3>Personal Time-Lapse</h3>
            <p>
              Nhan Tran, Ethan Yang, Angelique Taylor, Abe Davis<br>
                <i>UIST 2024: ACM Conference on User Interface Software and Technology</i><br>
                <a href="https://www.cs.cornell.edu/abe/projects/mecapture/">Project</a>&nbsp;
                <a href="https://dl.acm.org/doi/10.1145/3654777.3676383">PDF</a>&nbsp;&nbsp;&nbsp;&nbsp;
            </p>

            <p>
              We present a mobile augmented reality tool that uses custom 3D tracking, interactive visual feedback, and computational imaging to capture personal time-lapses. These time-lapses approximate long-term videos of a subject (typically part of the user's body) under consistent viewpoint, pose, and lighting, providing a convenient way to document and visualize long-term changes in the body, with many potential applications in remote healthcare and telemedicine.
            </p>
          </div>
        </div>

        <div class="list-item publication" data-category="publication" id="arcomm">
          <a href="#arcomm" class="thumbnail">
            <img src="/images/research/mixedrobot-1.gif" alt="" />
          </a>
          <div class="project-description">
            <h3><a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2022/12/tran2023vamr.pdf">Now Look Here! ⇓ Mixed Reality Improves Robot Communication Without Cognitive Overload</a></h3>
            </a></h3>
            
            <p>
              Nhan Tran, Trevor Grant, Thao Phung, Leanne Hirshfield, Christopher Wickens, Tom Williams<br>
                <i>HCI International Conference on Virtual, Augmented, and Mixed Reality (HCII 2023) </i><br>
                <a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2022/12/tran2023vamr.pdf">PDF</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
            </p>
            
            <p>
              We explored whether the success of Mixed Reality Deictic Gestures for human-robot communication depends on a user's cognitive load, through an experiment grounded in theories of cognitive resources. We found these gestures provide benefits regardless of cognitive load, but only when paired with complex language. Our results suggest designers can use rich referring expressions with these gestures without overloading users.            
            </p>
          </div>
        </div>

        <div class="list-item publication" data-category="publication" id="arpointing">
          <a href="#arpointing" class="thumbnail">
            <img src="/images/research/demo_ar_gesture.gif" alt="" />
          </a>
          <div class="project-description">
            <h3><a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2020/12/hamilton2021hri.pdf">What's The Point? Tradeoffs Between Effectiveness and Social Perception When Using Mixed Reality to Enhance Gesturally Limited Robots</a></h3>
            <p>
              Jared Hamilton, Thao Phung, Nhan Tran, Tom Williams<br>
                <i>ACM/IEEE International Conference on Human-Robot Interaction (HRI 2021)</i><br>
                <a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2020/12/hamilton2021hri.pdf">PDF</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  We present the first experiment analyzing the effectiveness of robot-generated mixed reality gestures using real robotic and mixed reality hardware. Our findings demonstrate how these gestures increase user effectiveness by decreasing user response time during visual search tasks, and show that robots can safely pair longer, more natural referring expressions with mixed reality gestures without worrying about cognitively overloading their interlocutors.
                </p>
            </p>
          </div>
        </div>

        <div class="list-item publication" data-category="publication">
          <a href="#" class="thumbnail">
            <img src="/images/research/hri_ar_exp_setup2019.png" alt="" />
          </a>
          <div class="project-description">
            <h3><a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2021/01/tran_pioneers.pdf">Adapting Mixed Reality Robot Communication to Mental Workload</a></h3>
            <p>
             Nhan Tran<br>
                <i>HRI Pioneers Workshop at the International Conference on Human-Robot Interaction (HRI 2020)</i><br>
                <font color="49bf9"><i>★ HRI Pioneers ★</i></font>
                <a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2021/01/tran_pioneers.pdf">PDF</a>&nbsp;&nbsp;&nbsp;&nbsp;
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <br>
            </p>
          </div>
        </div>

        <div class="list-item publication" data-category="publication">
          <a href="#" class="thumbnail">
            <img src="/images/research/hri2019.png" alt="" />
          </a>
          <div class="project-description">
            <h3><a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2019/02/williams2019hri.pdf">Mixed reality deictic gesture for multi-modal robot communication</a></h3>
            <p>
              Tom Williams and Matthew Bussing and Sebastian Cabrol and Elizabeth Boyle and Nhan Tran<br>
                <i>ACM/IEEE International Conference on Human-Robot Interaction (HRI 2019)</i><br>
                <a href="https://mirrorlab.mines.edu/wp-content/uploads/sites/198/2019/02/williams2019hri.pdf">PDF</a>&nbsp;&nbsp;&nbsp;&nbsp;
            </p>
            <p>
              We investigate human perception of videos simulating the display of allocentric gestures, in which robots circle their targets in users' fields of view. Our results suggest that this is an effective communication strategy, both in terms of objective accuracy and subjective perception, especially when paired with complex natural language references.            </p>
          </div>
        </div>

        <div class="list-item publication" data-category="publication">
          <a href="#" class="thumbnail">
            <img src="/images/research/demo_categories_mixed_reality_gestures.webp" alt="" />
          </a>
          <div class="project-description">
            <h3><a href="https://dyalab.mines.edu/papers/williams2018augmented.pdf">Augmented, mixed, and virtual reality enabling of robot deixis</a></h3>
            <p>
              Tom Williams, Nhan Tran, Josh Rands, Neil T Dantam<br>
                <i>HCI International Conference on Virtual, Augmented, and Mixed Reality (2018)</i><br>
                <a href="https://dyalab.mines.edu/papers/williams2018augmented.pdf">PDF</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
            </p>
            <p> Humans use deictic gestures like pointing when interacting to help identify targets of interest. Research shows similar robot gestures enable effective human-robot interaction. We present a conceptual framework for mixed-reality deictic gestures and summarize our work using these techniques to advance robot-generated deixis state-of-the-art</p>
          </div>
        </div>

        <!-- Films and Videos -->

        <div class="section-title list-item " data-category="talk">
          <h2 id="filmmaking">Films & Videos</h2>
        </div>

        <div class="list-item talk description" data-category="talk">
          <p>Outside of my research, creating videos has been a long-time creative outlet. Through Cornell's Cinematography program, I've had the chance to wear many hats—writer/director, director of cinematography, assistant camera (AC) operator, gaffer, lighting, art departments, and editor. These experiences have given me a deep appreciation for the filmmaking process, from scripting in pre-production, working with actors on set, to fine-tuning the edit in post-production. In many ways, these roles inform my research, motivating me to improve creative workflows and address the pain points that content creators face throughout the process.
          </p>
          <br />
          <p> Some of the films I've worked on can be found below or on my  <a href="https://www.youtube.com/@NhanTrann/videos">YouTube channel</a>. Please note, these are student productions with zero budget—but plenty of passion!</p>
        </div>

        <div class="video-grid list-item talk"  data-category="talk">
          <!-- Repeat this block for each video -->

          <div class="video-item">
            <div class="video-title">Für Elise | A 2-minute short film</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/Nsda-ccAB-w" allowfullscreen></iframe>
            </div>
          </div>

          <div class="video-item">
            <div class="video-title">The Tiny Explorer | A short film by Waki Kamino, Peter Wu, Nhan Tran</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/P5E4S3lWXL4" allowfullscreen></iframe>
            </div>
          </div>

          <div class="video-item">
            <div class="video-title">Solar Eclipse | Chimney Bluffs State Park</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/dli55L8Lxac" allowfullscreen></iframe>
            </div>
          </div>

          <div class="video-item">
            <div class="video-title">The Phantom of Gates Hall | An Otamatone Performance</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/2AtDj1o34z4" allowfullscreen></iframe>
            </div>
          </div>

          <div class="video-item">
            <div class="video-title">Short Films Teaser 2023 | "The Tiny Explorer", "My Robot", "Facade"</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/qcZG6xPth_Q" allowfullscreen></iframe>
            </div>
          </div>

          <div class="video-item">
            <div class="video-title">MY ROBOT | A 2-minute short film</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/Wj3IVdL4kJ4" allowfullscreen></iframe>
            </div>
          </div>

          <div class="video-item">
            <div class="video-title">16mm Film Experiment</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/LQYDwJy3n8Y" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Spaced Out | A Short Movie</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/H16iTqMmSwA" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Inclusive User Testing in VR | MIT Reality Hack 2022</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/Ya5j5WeGvrk" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item" id="xrhospitalrobot">
            <div class="video-title">XR-Controlled Hospital Robot Prototype</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/3wOhbuREGDs" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Inclusive User Testing in VR | MIT Reality Hack 2022</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/sWlZ16S7u6k" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">MusicBlox: Tangible Programming in Mixed Reality | AR/VR Grand Prize @ Stanford TreeHacks 2020</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/5111AfNnS1A" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Melody Mesh | 3D Audio Visualizer</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/tZ67UvLzx2w" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Pandemic Simulator (Cornell CS5620 Creative Project 1)</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/y5r7bS04Zk0" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Physics Things - Short Horror Movie </div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/S1RVDtXrVOU" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Blasterbotica 2016 NASA Robotic Mining Competition</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/hPARYsAKzIY" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Mines Robotics Recognized for Best Robot at 2017 CO Space Grant Robotics Challenge</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/iZPNegBoQLA" allowfullscreen></iframe>
            </div>
          </div>
          <div class="video-item">
            <div class="video-title">Mines Robotics WON FIRST PLACE at 2017 ASME Robot Pentathlon - Student Design Competition</div>
            <div class="video-container">
              <iframe src="https://www.youtube.com/embed/WdhZEivyo0g" allowfullscreen></iframe>
            </div>
          </div>

        </div>


        <!-- Misc  -->
        <div class="section-title list-item " data-category="misc">
          <h2>Misc Projects</h2>
        </div>

        <div class="list-item misc description" data-category="misc">
          Did I mention I enjoy rapid prototyping? From hardware to software to AR/VR, I love tinkering with electronics, AR/VR headsets, and any tech gadgets I can get my hands on. Over weekends, at hackathons with friends, and during outreach events where I teach kids about these technologies, I’ve built several small projects. These hands-on experiences have been not only fun but also incredibly valuable in shaping how I approach problem-solving and learning.          <br />
        </div>
        
        <div class="list-item misc" data-category="misc" id="visionSliceBot">
          <a href="images/projects/visionslicebot_web_teaser.mp4" class="thumbnail">
            <video class="preview2" playsinline="" muted="" autoplay="" loop=""><source src="images/projects/visionslicebot_web_teaser.mp4" type="video/mp4"></video>
          </a>
          <div class="project-description">
            <h3>Vision Slice Bot: Generalized Food Cutting with User Inputs</h3>
            <a href="https://www.youtube.com/watch?v=VfwPClEmxfU" target="_blank">Full Demo Video </a>
                <p>
                  My four classmates and I developed a vision-based, one-armed robot capable of tracking and manipulating user-specified food items for precise cutting tasks. Built on top of the open-vocabulary semantic segmentation model <a href="https://huggingface.co/docs/transformers/en/model_doc/clipseg" target="_blank">CLIPSeg</a>, it can precisely track and cut a variety of fruits and vegetables. Our <a href="https://youtu.be/VfwPClEmxfU">demo video</a>, shows it in action, detecting, grasping, moving, and cutting foods according to user prompts. Project in the graduate Robot Manipulation class taught by <a href="https://sites.google.com/site/tapomayukh">Prof. Tapo Bhattacharjee</a>.
                
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc" id="worldgpt">
          <a href="#worldgpt" class="thumbnail">
            <img src="/images/misc/worldGPT.gif" alt="" />
          </a>
          <div class="project-description">
            <h3>World GPT</h3>
            <a href="https://youtu.be/5DcABeOltL8" target="_blank">West World inspired teaser video</a>
                <p>
                  Built in 6 hours at Cornell Tech's first AI Hackathon (April 2023) with 5 team members. We created a Unity virtual world where agents simulate memories, have unscripted conversations, and demonstrate emergent interactions using GPT-3. Before the real time live demo, we had 15 minute to put together a <a href="https://youtu.be/5DcABeOltL8"> video here</a>, inspired by HBO West World.
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc" id="hospitalrobot">
          <a href="#hospitalrobot" class="thumbnail">
            <video class="preview2" playsinline="" muted="" autoplay="" loop=""><source src="images/projects/hospital_robot_sequence2.m4v" type="video/mp4"></video>
          </a>
          <div class="project-description">
            <h3><a href="#">Robotic Medical Crash Cart</a></h3>
            <a href="https://youtube.com/shorts/Q9__oWKzZ7E">Video 1 (Hardware)  </a>
            <a href="https://youtube.com/shorts/8DgEADBXTwM">Video 2 (Pilot Study) </a>

                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  I led this project with a team of undergraduates to transform a medical crash cart used in hospitals into a smart robotic system as part of the Mobile Human-Robot Interaction class taught by <a href="https://wendyju.com/">Prof. Wendy Ju</a> at Cornell Tech. The base is built on a modified hoverboard. On the perception side, we use the RealSense depth sensor to prototype the "follow me" interaction robot that carries medical supplies and follows designated user.              
                </p>
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
                <br >
          </div>
        </div>

        <div class="list-item misc" data-category="misc" id="wallz">
          <a href="" class="thumbnail">
            <img src="/images/misc/wall-z3.gif" alt="" />
          </a>
          <div class="project-description">
            <h3>Wall Z 1.0</h3>
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  My friend Ryan and I built the Wall-Z robot, inspired by Disney's Wall-E, which uses on-edge processing with an Nvidia Jetson for ASL recognition, VR for remote environment visualization, and synchronizes its head movement with a VR headset.
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc">
          <a href="" class="thumbnail">
            <img src="/images/misc/pill_tracker.gif" alt="" />
          </a>
          <div class="project-description">
            <h3>Mixed-Reality Assistant for Medication Navigation and Tracking</h3>
                <a href="https://github.com/megatran/HoloLens_Pill_Tracker">Code</a>
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  I built an embodied mixed reality assistant on the Microsoft HoloLens 1 that uses virtual interfaces to allow users to anchor where they placed their pill bottles, saves the locations in a map, and then when requested, projects an overlay of the shortest path from the user's current position to the saved anchor points.
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc">
          <a href="" class="thumbnail">
            <img src="/images/misc/spacegrant_robot.gif" alt="" />
          </a>
          <div class="project-description">
            <h3>3D-printed Mars Rover</h3>
                <a href="https://youtu.be/iZPNegBoQLA">Video</a>
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  Team project with the Mines Robotics Club. We built a tiny Mars rover to compete in the Colorado Space Grant Robotics Challenge. The robot used several proximity sensors to avoid obstacles, drive toward a beacon, and withstand the Mars-like environment of the Great Sand Dunes National Park. 
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc" id="blasterbotica">
          <a href="" class="thumbnail">
            <img src="/images/projects/blasterbotica.webp" alt="" />
          </a>
          <div class="project-description">
            <h3>Blasterbotica: The Mining Bot at the NASA Robotic Mining Competition</h3>
                <a href="https://youtu.be/hPARYsAKzIY">Video</a>
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  Built with the Colorado School of Mines’ Blasterbotica senior design team to compete in the NASA Robotic Mining Competition. This robot could traverse the arena, avoid obstacles, excavate regolith, and dump the collected regolith into the final collection bin. I was the youngest member working closely with another senior team member to implement ROS+OpenCV pipeline to detect obstacles and the collection bin.
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc">
          <a href="#" class="thumbnail">
            <img src="/images/misc/biped-bot.gif" alt="" />
          </a>
          <div class="project-description">
            <h3>Biped Robot v1.5 - A DIY Humanoid Walking Robot</h3>
                <a href="https://youtu.be/iZPNegBoQLA">Video</a>
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  My friend Arthur and I built this biped robot over a weekend. It was designed to imitate human walking, detect obstacles, and be operated using hand gestures. This was after watching the debut of the Atlas robot at Boston Dynamics. Through DIY, we learned that bipedal locomotion is hard!
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc">
          <a href="" class="thumbnail">
            <img src="/images/misc/gesturedControlled_bot.gif" alt="" />
          </a>
          <div class="project-description">
            <h3>Hailfire, a hand gesture-controlled robot</h3>
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  I was learning how to interface from the web to an Arduino using Cylon.js. This prototype showcases how a robot can be operated using JavaScript and an accelerometer. I gave a lightning talk at the 2016 O'Reilly Fluent Conference about this project.
                </p>
          </div>
        </div>

        <div class="list-item misc" data-category="misc">
          <a href="#" class="thumbnail">
            <img src="/images/misc/drinkmixer.gif" alt="" />
          </a>
          <div class="project-description">
            <h3>Sir Mixer: An emotionally aware bartender robot</h3>
                <a href="https://youtu.be/ifw9tQVKnvM">Video</a>
                <br> <!-- TODO: extra spaces until I figure out the margin bug. -->
                <p>
                  My roommate Patrick and I built an IoT drink mixer that is able to interpret the facial expressions of human users, infer their emotions, and then mix drinks accordingly.              
                </p>
                <br>
                <br>
          </div>
        </div>

    </div>

      <div id="footer">Academic template from <a href="https://andyzeng.github.io">Andy Zeng</a>. Inspired by <a href="https://jonbarron.info/">Jon's website</a>.</div>

    </div>

    <script>

      // Preloader
      $(document).ready(function() {
        // Initially set the body class to loading
        $('body').addClass('loading');

        // Hide the preloader and show the content after 1 second
        setTimeout(function() {
          $('#preloader').fadeOut('fast');
          $('body').removeClass('loading');
        }, 1329); // 1000ms = 1 second
      });

      // Isotope grid.
      var $grid = $('.grid').isotope({
        itemSelector: '.list-item',
        layoutMode: 'fitRows',
        transitionDuration: 0,
        stagger: 10,
        initLayout: false,
        getSortData: {
          name: '.name',
          symbol: '.symbol',
          number: '.number parseInt',
          category: '[data-category]',
          weight: function( itemElem ) {
            var weight = $( itemElem ).find('.weight').text();
            return parseFloat( weight.replace( /[\(\)]/g, '') );
          }
        }
      });

      // Bind filter button click.
      $('#filters').on( 'click', 'button', function() {
        var filterValue = $( this ).attr('data-filter');
        localStorage.setItem('filterValue', filterValue);
        $grid.isotope({ filter: filterValue });
      });

      // Change is-checked class on buttons.
      $('.button-group').each( function( i, buttonGroup ) {
        var $buttonGroup = $( buttonGroup );
        $buttonGroup.on( 'click', 'button', function() {
          $buttonGroup.find('.is-checked').removeClass('is-checked');
          $( this ).addClass('is-checked');
        });
      });

      function update_isotope() {
        // Retrieve cached button click.
        var defaultFilterValue = localStorage.getItem('filterValue');
        if (defaultFilterValue == null) {
          defaultFilterValue = "*"
        }
        $grid.isotope({ filter: defaultFilterValue });
        var buttons = document.getElementsByClassName("button");
        for (var currButton of buttons) {
          if (currButton.getAttribute('data-filter') == defaultFilterValue) {
            currButton.classList.add('is-checked');
          } else {
            currButton.classList.remove('is-checked');
          }
        }
      }

      function toggle_bio() {
        var x = document.getElementById("more-bio");
        if (x.style.display === "none") {
          x.style.display = "block";
        } else {
          x.style.display = "none";
        }
      }

      function toggle_highlights() {
        var x = document.getElementById("main-highlights");
        var y = document.getElementById("more-highlights");
        var b = document.getElementById("toggle_highlights_button")
        if (y.style.display === "none") {
          x.style.display = "none";
          y.style.display = "block";
          b.innerHTML = "Show less"
          update_isotope();
        } else {
          x.style.display = "block";
          y.style.display = "none";
          b.innerHTML = "Show more"
          update_isotope();
        }
      }

      $('#filters').on('click', 'button', function() {
        var filterValue = $(this).attr('data-filter');

        // Show section titles only when "Show All" is selected
        if (filterValue === '*') {
          $('.section-title').show();
        } else {
          $('.section-title').hide();
        }

        // Proceed with the normal Isotope filtering
        $grid.isotope({ filter: filterValue });
      });


      update_isotope();

    </script>
  </body>
</html>
